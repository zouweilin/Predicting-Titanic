{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # pretty visualizations\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#First I'm going to get the files as a DataFrame\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n#We'll need this later to submit the result\ntest2 = test.copy()\nfull_data = [train,test]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "57118be4274798c40b5a9e69049af19fb6c4bcf6",
        "_cell_guid": "349b1d55-0188-47e7-aab3-3848dd70c7c8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Let's see the data that we're working with.\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9d099cf6431c9f4fbec8337f04d3fb6cc4825849",
        "_cell_guid": "93ba8415-cde1-4f52-919a-67c53f2c5404",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#How much data do we have?\ntrain.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "881c6b3519e834963b090f4e4ddb173dac54b084",
        "_cell_guid": "4e481f36-6770-4eef-9809-5386227f5b1b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Lets see what we have to work with\ntrain.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5b6148a98d4de0cbb26c054cf151d8473f243dbb",
        "_cell_guid": "4b7a2f64-4657-4ca8-a8ec-e4b89a84246b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#We can reality check the data to see if it makes sense. The average age with 29 years old, the youngest person  was less than a year old and the\n#oldest is 80 years old. The fare price varied drammatically from the minimum fare of free to 512. We can also see what data is missing\ntrain.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "53679f59735c4929c991dd3122e2e826b31cb661",
        "_cell_guid": "ba228053-b4c4-45d4-b31f-b263c4a6b145",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#We can see that we only have very little data for \"Cabin\"\ntrain.describe(include=\"O\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "08dd7eaa1574881a71a72936643470a5f96439bc",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Lets see which variables have an impact on survival so we can put them into our model\ntrain[['Pclass','Survived']].groupby(['Pclass']).mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a8ea1a2955628138f886ef67bbccf65299d643c0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#We can see class is highly correlated to survival so we should probably include that in our model\n#What about sex?\ntrain[['Sex','Survived']].groupby(['Sex']).mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7b0011388a2e19822bf68cf0ef7055ae74ad8b6f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#We can see this is probably one of the most important determinants to surival so we'll include that too\n#'SibSp' and 'Parch' refer to the siblings/spouses and parents/children on the ship respectively. We're not missing\n#Any data for those two variables so lets make a new variable called \"FamilySize\"\nfor dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\ntrain[['FamilySize','Survived']].groupby(['FamilySize']).mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2bc87ac2c930f7e500a376384e6b590bda415255",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#It looks to be pretty correlated, but I'm not entirely sure about the direction the correlation is going in or how much randomness is a\n#factor in these variables since the survival for FamilySize ==4 is over 70% whereas it drops to around 15-30% for those over 5\n# Lets make a new variable \"IsAlone\" based on if the familysize is one or not\nfor dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain[['IsAlone','Survived']].groupby(['IsAlone']).mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fcaf6cf26da6e86e0e15be7e3016aac3a9fb0c97",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#This one seems pretty good\n#Lets look at the next one, which is 'Age', which would make sense if it is correlated with survival\nfacet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d00d531bd4f0e3c48c64403492e3cc1d4544f618",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Age looks pretty correlated with survival, esepcially for children, who are more likely to survive, and the elderly, who may not be.\n#This one seems pretty good\n#Lets look at the next one, which is 'Age', which would make sense if it is correlated with survival\nfacet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aec69cf805c141801dd9965c901a5e336e9ee0c6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#It definitely looks like higher fares are associated with survival, although it is a bit harder to tell at the tail where the graph is skewed.\n#Let's break it down into four segments and see if we can see it more clearly that way\ntrain['FareCategories'] = pd.qcut(train['Fare'],4)\ntrain[['FareCategories','Survived']].groupby(['FareCategories']).mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4131d12724e260adbc8fcd8bc3e1a00b46c8a07a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#We can definitely see an increase in survival as the fare increases\n#Not sure what we can do with Cabin and Ticket so lets skip those for now and go to Embarked\ntrain[['Embarked','Survived']].groupby(['Embarked']).mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "e3723b3d53714e1e7aa5f4e65cef359030d1dbee",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#It definitely looks correlated, but logically it doesn't really make sense to me unless it's because it's also correlated with one of our\n#other factors somehow\n#Now that we have the factors that we want to include, lets drop the columns that we don't need anymore\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch', 'FamilySize','Embarked']\n#We need to also to remember to drop elements from 'FareCategories' since we made that column earlier to visualize our data a little better\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['FareCategories'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "02fc43f3bca22c6dc6d97be67db6d76091fa7940",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#We still have many missing values in our \"Age\" category \n#Let's fill the missing values with the mean value for Age\ntrain[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())\ntest[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())\ntrain['Age'].describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "14fb7e209d58cf8e635e83d5f8db17e74998c0e6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#We have one missing value for the \"Fare\" column for the test column so we'll fill it in with the mean()\ntest[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "d133e11ceedecbcb4238047f8fa0b6bfbfd1db5a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train['Sex'] = train['Sex'].map( {'female': 0, 'male': 1} )\ntest['Sex'] = test['Sex'].map( {'female': 0, 'male': 1} )\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "b3d8c7a0feef7d1540cce9dcafaf4e8434d109ac",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Our dataset looks good for running our machine learning models on now\nX = train.drop(\"Survived\", axis = 1)\nY = train[\"Survived\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "c6dbf24c245141cad85471156d1e17e8acadf3b2",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Lets try out these machine learning models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n# going to split the data to avoid overfitting so we can pick the best model\nfrom sklearn.cross_validation import train_test_split",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "e907408f5e9516babb3ce6eb6bc712124a5f3fd7",
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e1ff3964a0f586d8fc4e7c2a9385d680f7805e13",
        "trusted": false
      },
      "cell_type": "code",
      "source": "logreg = LogisticRegression()\n\nlogreg.fit(X_train, Y_train)\n\nlogreg.score(X_test, Y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "02decfef2581fa02fafcea3201f5afeb08501b64",
        "trusted": false
      },
      "cell_type": "code",
      "source": "random_forest = RandomForestClassifier()\n\nrandom_forest.fit(X_train, Y_train)\n\nrandom_forest.score(X_test, Y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6d9bdd1579fc27005f8e0706d1585e8287ec3441",
        "trusted": false
      },
      "cell_type": "code",
      "source": "svc = SVC()\n\nsvc.fit(X_train, Y_train)\n\nsvc.score(X_test, Y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0c451dc61aa13a55c9ae1b611de5b9292030cf5e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier(n_neighbors = 3)\n\nknn.fit(X_train, Y_train)\n\nknn.score(X_test, Y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "08a70c226767b794cdaa928b15a6ec0b4712c0e4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\n\ngaussian.score(X_test, Y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "37ab3320088975c87471d3e2f9d3a21e922a4822",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#I think we'll want to use the random forest model, so we'll retrain it using the entire training set, run it on our test set and submit it!\nrandom_forest_real = RandomForestClassifier()\nrandom_forest_real.fit(X, Y)\nY_pred = random_forest_real.predict(test)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "a04a92df576d140971eb62fca6ae56f845be2a02",
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission = pd.DataFrame({\n        \"PassengerId\": test2[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('titanic_submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "version": "3.6.4",
      "name": "python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}